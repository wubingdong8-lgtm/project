import type { NextApiRequest, NextApiResponse } from 'next'; // æ”¹ç”¨ Node ç‰ˆçš„åž‹åˆ¥
import { type MessageList } from "@/types";
import { createParser, ParsedEvent, ReconnectInterval } from "eventsource-parser";
import { MAX_TOKEN, TEAMPERATURE } from "@/utils/constant";
import { retrieveContext } from '../../utils/rag'; // å¼•å…¥ RAG

// å¼·åˆ¶ä½¿ç”¨ Node.js Runtime (é€™æ¨£ Pinecone æ‰èƒ½è·‘)
export const config = {
  runtime: "nodejs", 
};

type StreamPayload = {
  model: string;
  messages: MessageList;
  temperature?: number;
  stream: boolean;
  max_tokens?: number;
}

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  // 1. ã€ä¿®æ­£è¼¸å…¥ã€‘Node.js ç‰ˆç›´æŽ¥ç”¨ req.bodyï¼Œä¸éœ€è¦ await req.json()
  const { prompt, history = [], options = {} } = req.body;
  const { max_tokens, temperature } = options;

  // ==========================================
  // ðŸ”¥ RAG é‚è¼¯
  // ==========================================
  const context = await retrieveContext(prompt);
  let systemPrompt = options.prompt || "ä½ æ˜¯ä¸€å€‹æœ‰ç”¨çš„ AI åŠ©æ‰‹";

  if (context) {
    console.log("ðŸ” [RAG] ç³»çµ±è£œå……è³‡æ–™é•·åº¦:", context.length);
    systemPrompt += `\n\nã€ç³»çµ±è£œå…… - å…§éƒ¨çŸ¥è­˜åº«ã€‘ï¼š\n${context}\n\nè«‹å„ªå…ˆä¾æ“šä¸Šè¿°è£œå……è³‡è¨Šå›žç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚`;
  }
  // ==========================================

  const data = {
    model: "gpt-3.5-turbo",
    messages: [
      { role: "system", content: systemPrompt },
      ...history,
      { role: "user", content: prompt },
    ],
    stream: true,
    temperature: +temperature || TEAMPERATURE,
    max_tokens: +max_tokens || MAX_TOKEN,
  };

  // 2. ã€ä¿®æ­£è¼¸å‡ºã€‘è¨­å®š Headers å‘Šè¨´ç€è¦½å™¨é€™æ˜¯ä¸€æ¢ä¸²æµ (Stream)
  res.writeHead(200, {
    'Content-Type': 'text/event-stream',
    'Cache-Control': 'no-cache, no-transform',
    'Connection': 'keep-alive',
  });

  try {
    // å‘¼å« OpenAI ä¸¦å–å¾—ä¸²æµ
    const stream = await requestStream(data);
    
    // 3. ã€ä¿®æ­£ä¸²æµå¯«å…¥ã€‘å°‡ Web Stream è½‰ç™¼çµ¦ Next.js çš„ res (Node.js Writable)
    const reader = stream.getReader();
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      // é€™è£¡çš„ value æ˜¯ Uint8Arrayï¼Œç›´æŽ¥å¯«å…¥ response
      res.write(value);
    }
  } catch (error) {
    console.error("Stream Error:", error);
    res.write("ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦");
  } finally {
    res.end(); // çµæŸé€£ç·š
  }
}

// ðŸ‘‡ ä»¥ä¸‹æ˜¯ Helper Functions (å¾®èª¿é©é… Node ç’°å¢ƒ) ðŸ‘‡

const requestStream = async(payload: StreamPayload) => {
  let counter = 0;
  // ç¢ºä¿ baseUrl æ°¸é æœ‰ä¸€å€‹åˆæ³•çš„é è¨­å€¼
  const rawBaseUrl = process.env.END_POINT?.trim();
  const baseUrl = (rawBaseUrl && rawBaseUrl !== "") ? rawBaseUrl : "https://api.openai.com";

  const resp = await fetch(`${baseUrl}/v1/chat/completions`, {
    headers: {
      Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      "Content-Type": "application/json",
    },
    method: "POST",
    body: JSON.stringify(payload),
  });

  if (resp.status !== 200) {
    throw new Error(`OpenAI API Error: ${resp.statusText}`);
  }

  // é€™è£¡å›žå‚³æ¨™æº–çš„ ReadableStream
  return createStream(resp, counter);
};

const createStream = (response: Response, counter: number) => {
  const decoder = new TextDecoder("utf-8");
  const encoder = new TextEncoder();
  
  return new ReadableStream({
    async start(controller) {
      const onParse = (event: ParsedEvent | ReconnectInterval) => {
        if (event.type === "event") {
          const data = event.data;
          if(data === "[DONE]") {
            controller.close();
            return;
          }
          try {
            const json = JSON.parse(data)
            const text = json.choices[0]?.delta?.content || "";
            if(counter < 2 && (text.match(/\n/) || [].length)){
              return;
            }
            const q = encoder.encode(text);
            controller.enqueue(q);
            counter++;
          } catch (error){}
        }
      };

      const parser = createParser(onParse);

      // Node.js çš„ fetch polyfill ç”¢ç”Ÿçš„ body ä¹Ÿæ˜¯ async iterable
      for await (const chunk of response.body as any) {
        parser.feed(decoder.decode(chunk));
      }
    },
  });
};